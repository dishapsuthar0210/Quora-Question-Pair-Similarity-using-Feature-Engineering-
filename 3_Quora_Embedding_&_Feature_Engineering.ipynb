{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1644585091097,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSpfk3evOnQu4WaAr65Jsk94o0T_MicRlfD3-hAVs=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "-3IbomL8dMTi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HbiMFpgRdMUJ",
    "outputId": "21c00698-7f2a-4ce4-e665-f7a2feaab6fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23761,
     "status": "ok",
     "timestamp": 1644585114855,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSpfk3evOnQu4WaAr65Jsk94o0T_MicRlfD3-hAVs=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "PFS6m8z5dMUz",
    "outputId": "c166e549-80be-4a79-95e3-9ea65a191971"
   },
   "outputs": [],
   "source": [
    "def get_weighted_embedding(texts, word2tfidf, model, batch_size):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        \n",
    "    all_embeddings = []\n",
    "    texts_len = len(texts)\n",
    "    for i in range(0, texts_len, batch_size):\n",
    "        # print(f'Processing batch: {i // batch_size}')\n",
    "        batch = texts[i:i+batch_size]\n",
    "        # Compute average TF-IDF weight per text\n",
    "        avg_weights = []\n",
    "        for text in batch:\n",
    "            words = text.split()\n",
    "            if words:\n",
    "                weights = [word2tfidf.get(w, 0) for w in words]\n",
    "                avg_weights.append(sum(weights) / len(weights))\n",
    "            else:\n",
    "                avg_weights.append(0.0)\n",
    "        avg_weights = torch.tensor(avg_weights, device=device)\n",
    "        \n",
    "        # Encode batch to sentence embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.encode(batch, convert_to_tensor=True, device=device)\n",
    "\n",
    "        # Scale embeddings by average weights\n",
    "        weighted_embeddings = embeddings * avg_weights.unsqueeze(1)\n",
    "        all_embeddings.extend(weighted_embeddings.detach().cpu().numpy())\n",
    "        try:\n",
    "            del batch, embeddings, weighted_embeddings\n",
    "        except NameError:\n",
    "            pass\n",
    "\n",
    "    # print(np.array(all_embeddings).shape, type(all_embeddings), type(all_embeddings[0]))\n",
    "    return all_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "62GEF-RbdMVB",
    "outputId": "60a4f5f8-5582-4886-befd-2ab6ed99c753"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('nlp_vector_dataframe.joblib'):\n",
    "    print('Loading vector dataframe from the file.')\n",
    "    df = joblib.load('nlp_vector_dataframe.joblib')\n",
    "else:\n",
    "    df['qu1_feats_m'] = get_weighted_embedding(\n",
    "        df['question1'].values, word2tfidf, model, batch_size=2**13)\n",
    "    df['qu2_feats_m'] = get_weighted_embedding(\n",
    "        df['question2'].values, word2tfidf, model, batch_size=2**13)\n",
    "    df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1,inplace=True)\n",
    "    joblib.dump(df, 'nlp_vector_dataframe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290,)\n",
      "(404290,)\n"
     ]
    }
   ],
   "source": [
    "print(df['qu1_feats_m'].shape)\n",
    "print(df['qu2_feats_m'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(df['qu1_feats_m'][0].shape)\n",
    "print(df['qu2_feats_m'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df\n",
    "df3_q1 = pd.DataFrame(df3['qu1_feats_m'].values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3['qu2_feats_m'].values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xzWAqGegdMVp",
    "outputId": "2f88eeda-244f-4bbb-a51c-a8680fe8fb92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           2.0      13.0   \n",
       "1  0.466664           0.0            1.0           5.0      12.5   \n",
       "2  0.285712           0.0            1.0           4.0      12.0   \n",
       "3  0.000000           0.0            0.0           2.0      12.0   \n",
       "4  0.307690           0.0            1.0           6.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0              100                93          93                 100   \n",
       "1               86                63          66                  75   \n",
       "2               63                63          43                  47   \n",
       "3               28                24           9                  14   \n",
       "4               67                47          35                  56   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982759  \n",
       "1              0.596154  \n",
       "2              0.166667  \n",
       "3              0.039216  \n",
       "4              0.175000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N4DQnDtndMV4",
    "outputId": "2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "0   0          1          1     66     57          14          12   \n",
       "1   1          4          1     51     88           8          13   \n",
       "2   2          1          1     73     59          14          10   \n",
       "3   3          1          1     50     65          11           9   \n",
       "4   4          3          1     76     39          13           7   \n",
       "\n",
       "   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "0         10.0        23.0    0.434783           2           0  \n",
       "1          4.0        20.0    0.200000           5           3  \n",
       "2          4.0        24.0    0.166667           2           0  \n",
       "3          0.0        19.0    0.000000           2           0  \n",
       "4          2.0        20.0    0.100000           4           2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_1YIPtTwdMWC",
    "outputId": "510f4c73-0706-4633-d706-e0d348ebfa71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320846</td>\n",
       "      <td>-0.186737</td>\n",
       "      <td>-0.287031</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>-0.276487</td>\n",
       "      <td>0.257875</td>\n",
       "      <td>0.084914</td>\n",
       "      <td>0.116474</td>\n",
       "      <td>-0.499918</td>\n",
       "      <td>-0.104155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235298</td>\n",
       "      <td>0.379984</td>\n",
       "      <td>-0.405718</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>-0.133902</td>\n",
       "      <td>-0.235007</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>-0.197978</td>\n",
       "      <td>-0.309128</td>\n",
       "      <td>0.177339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.162865</td>\n",
       "      <td>0.539825</td>\n",
       "      <td>-0.136423</td>\n",
       "      <td>0.169766</td>\n",
       "      <td>-0.187270</td>\n",
       "      <td>-0.038557</td>\n",
       "      <td>-0.115679</td>\n",
       "      <td>-0.172218</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>-0.080888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119570</td>\n",
       "      <td>-0.029279</td>\n",
       "      <td>-0.072696</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>-0.205621</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>0.282377</td>\n",
       "      <td>-0.115446</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.139131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.111571</td>\n",
       "      <td>0.146567</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>0.070013</td>\n",
       "      <td>-0.302598</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>0.164734</td>\n",
       "      <td>0.088041</td>\n",
       "      <td>0.068868</td>\n",
       "      <td>-0.180420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104089</td>\n",
       "      <td>-0.298222</td>\n",
       "      <td>0.218934</td>\n",
       "      <td>-0.090424</td>\n",
       "      <td>-0.325695</td>\n",
       "      <td>0.448379</td>\n",
       "      <td>-0.338010</td>\n",
       "      <td>-0.263089</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>-0.065452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214366</td>\n",
       "      <td>-0.191116</td>\n",
       "      <td>0.155799</td>\n",
       "      <td>0.366758</td>\n",
       "      <td>0.126644</td>\n",
       "      <td>0.079277</td>\n",
       "      <td>0.335356</td>\n",
       "      <td>0.119631</td>\n",
       "      <td>0.248407</td>\n",
       "      <td>-0.112345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.189038</td>\n",
       "      <td>0.192116</td>\n",
       "      <td>0.403073</td>\n",
       "      <td>0.172075</td>\n",
       "      <td>0.039224</td>\n",
       "      <td>0.208773</td>\n",
       "      <td>0.104064</td>\n",
       "      <td>-0.268618</td>\n",
       "      <td>-0.315431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.285260</td>\n",
       "      <td>-0.149384</td>\n",
       "      <td>-0.211819</td>\n",
       "      <td>-0.013051</td>\n",
       "      <td>0.452586</td>\n",
       "      <td>-0.248367</td>\n",
       "      <td>0.280504</td>\n",
       "      <td>0.349548</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>-0.129971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134815</td>\n",
       "      <td>0.179587</td>\n",
       "      <td>-0.070858</td>\n",
       "      <td>-0.199728</td>\n",
       "      <td>-0.317968</td>\n",
       "      <td>-0.167555</td>\n",
       "      <td>0.561263</td>\n",
       "      <td>-0.228302</td>\n",
       "      <td>0.663638</td>\n",
       "      <td>-0.302125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.320846 -0.186737 -0.287031  0.035150 -0.276487  0.257875  0.084914   \n",
       "1 -0.162865  0.539825 -0.136423  0.169766 -0.187270 -0.038557 -0.115679   \n",
       "2 -0.111571  0.146567 -0.001577  0.070013 -0.302598  0.012227  0.164734   \n",
       "3  0.214366 -0.191116  0.155799  0.366758  0.126644  0.079277  0.335356   \n",
       "4 -0.285260 -0.149384 -0.211819 -0.013051  0.452586 -0.248367  0.280504   \n",
       "\n",
       "        7         8         9    ...       374       375       376       377  \\\n",
       "0  0.116474 -0.499918 -0.104155  ... -0.235298  0.379984 -0.405718  0.040615   \n",
       "1 -0.172218 -0.127867 -0.080888  ... -0.119570 -0.029279 -0.072696 -0.007461   \n",
       "2  0.088041  0.068868 -0.180420  ... -0.104089 -0.298222  0.218934 -0.090424   \n",
       "3  0.119631  0.248407 -0.112345  ...  0.012611  0.189038  0.192116  0.403073   \n",
       "4  0.349548  0.008555 -0.129971  ...  0.134815  0.179587 -0.070858 -0.199728   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0 -0.133902 -0.235007  0.003497 -0.197978 -0.309128  0.177339  \n",
       "1 -0.205621 -0.120081  0.282377 -0.115446  0.008669  0.139131  \n",
       "2 -0.325695  0.448379 -0.338010 -0.263089  0.016350 -0.065452  \n",
       "3  0.172075  0.039224  0.208773  0.104064 -0.268618 -0.315431  \n",
       "4 -0.317968 -0.167555  0.561263 -0.228302  0.663638 -0.302125  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wUMdkJTNdMWL",
    "outputId": "69e3e256-cbb8-4fe2-aaf2-9088c3868b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.423212</td>\n",
       "      <td>-0.164554</td>\n",
       "      <td>-0.270203</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>-0.216234</td>\n",
       "      <td>0.280429</td>\n",
       "      <td>0.047632</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>-0.476417</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171368</td>\n",
       "      <td>0.291435</td>\n",
       "      <td>-0.217767</td>\n",
       "      <td>0.099255</td>\n",
       "      <td>-0.071048</td>\n",
       "      <td>-0.177970</td>\n",
       "      <td>-0.037065</td>\n",
       "      <td>-0.205337</td>\n",
       "      <td>-0.267059</td>\n",
       "      <td>0.197239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.391221</td>\n",
       "      <td>0.747902</td>\n",
       "      <td>-0.065154</td>\n",
       "      <td>-0.177288</td>\n",
       "      <td>-0.066026</td>\n",
       "      <td>-0.031845</td>\n",
       "      <td>-0.185040</td>\n",
       "      <td>-0.287023</td>\n",
       "      <td>-0.160371</td>\n",
       "      <td>0.101577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243118</td>\n",
       "      <td>0.172128</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.377117</td>\n",
       "      <td>-0.371125</td>\n",
       "      <td>-0.119946</td>\n",
       "      <td>0.246193</td>\n",
       "      <td>-0.606370</td>\n",
       "      <td>-0.110116</td>\n",
       "      <td>-0.052228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.022114</td>\n",
       "      <td>-0.307914</td>\n",
       "      <td>0.281715</td>\n",
       "      <td>-0.186233</td>\n",
       "      <td>-0.593995</td>\n",
       "      <td>-0.194735</td>\n",
       "      <td>-0.066883</td>\n",
       "      <td>-0.252384</td>\n",
       "      <td>0.367712</td>\n",
       "      <td>-0.024775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222976</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>-0.012184</td>\n",
       "      <td>-0.021796</td>\n",
       "      <td>-0.325127</td>\n",
       "      <td>0.352813</td>\n",
       "      <td>-0.202566</td>\n",
       "      <td>-0.261915</td>\n",
       "      <td>0.147404</td>\n",
       "      <td>0.025606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234764</td>\n",
       "      <td>0.252844</td>\n",
       "      <td>-0.162482</td>\n",
       "      <td>0.058531</td>\n",
       "      <td>-0.048424</td>\n",
       "      <td>-0.179547</td>\n",
       "      <td>0.136423</td>\n",
       "      <td>0.190352</td>\n",
       "      <td>0.121681</td>\n",
       "      <td>0.023969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130749</td>\n",
       "      <td>-0.102055</td>\n",
       "      <td>-0.085348</td>\n",
       "      <td>-0.113203</td>\n",
       "      <td>0.071612</td>\n",
       "      <td>0.277859</td>\n",
       "      <td>-0.029385</td>\n",
       "      <td>-0.032677</td>\n",
       "      <td>0.244178</td>\n",
       "      <td>-0.313774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.305681</td>\n",
       "      <td>0.254926</td>\n",
       "      <td>-0.127245</td>\n",
       "      <td>-0.149993</td>\n",
       "      <td>-0.017058</td>\n",
       "      <td>-0.037423</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.127722</td>\n",
       "      <td>-0.181144</td>\n",
       "      <td>-0.279247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243170</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.143391</td>\n",
       "      <td>-0.209443</td>\n",
       "      <td>-0.718074</td>\n",
       "      <td>0.253778</td>\n",
       "      <td>-0.082368</td>\n",
       "      <td>0.072807</td>\n",
       "      <td>-0.012569</td>\n",
       "      <td>0.523109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.423212 -0.164554 -0.270203  0.104720 -0.216234  0.280429  0.047632   \n",
       "1 -0.391221  0.747902 -0.065154 -0.177288 -0.066026 -0.031845 -0.185040   \n",
       "2 -0.022114 -0.307914  0.281715 -0.186233 -0.593995 -0.194735 -0.066883   \n",
       "3  0.234764  0.252844 -0.162482  0.058531 -0.048424 -0.179547  0.136423   \n",
       "4 -0.305681  0.254926 -0.127245 -0.149993 -0.017058 -0.037423  0.091251   \n",
       "\n",
       "        7         8         9    ...       374       375       376       377  \\\n",
       "0  0.067348 -0.476417  0.013434  ... -0.171368  0.291435 -0.217767  0.099255   \n",
       "1 -0.287023 -0.160371  0.101577  ...  0.243118  0.172128  0.005463  0.377117   \n",
       "2 -0.252384  0.367712 -0.024775  ... -0.222976  0.040296 -0.012184 -0.021796   \n",
       "3  0.190352  0.121681  0.023969  ...  0.130749 -0.102055 -0.085348 -0.113203   \n",
       "4 -0.127722 -0.181144 -0.279247  ... -0.243170  0.231800  0.143391 -0.209443   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0 -0.071048 -0.177970 -0.037065 -0.205337 -0.267059  0.197239  \n",
       "1 -0.371125 -0.119946  0.246193 -0.606370 -0.110116 -0.052228  \n",
       "2 -0.325127  0.352813 -0.202566 -0.261915  0.147404  0.025606  \n",
       "3  0.071612  0.277859 -0.029385 -0.032677  0.244178 -0.313774  \n",
       "4 -0.718074  0.253778 -0.082368  0.072807 -0.012569  0.523109  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 11 features + id = 12 basic features\n",
    "- 15 adv. features + id + is_duplicate = 17 adv. features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ozz83vh4dMWU",
    "outputId": "e5b30f77-2849-4b08-9949-0912ec0db418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe : 17\n",
      "Number of features in preprocessed dataframe : 12\n",
      "Number of features in question1 w2v  dataframe : 384\n",
      "Number of features in question2 w2v  dataframe : 384\n",
      "Number of features in final dataframe  : 797\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmfZ5Q1zdMWl"
   },
   "outputs": [],
   "source": [
    "df3_q1['id']=df1['id']\n",
    "df3_q2['id']=df1['id']\n",
    "df1  = df1.merge(df2, on='id',how='left')\n",
    "df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "result  = df1.merge(df2, on='id',how='left')\n",
    "if not os.path.isfile('final_features.joblib'):\n",
    "    joblib.dump(result, 'final_features_dataframe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 796)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape\n",
    "# id is same for all dfs, so the final shape has 1 column less\n",
    "# than the sum of individual shapes after the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'is_duplicate', 'cwc_min', 'cwc_max', 'csc_min', 'csc_max',\n",
       "       'ctc_min', 'ctc_max', 'last_word_eq', 'first_word_eq',\n",
       "       ...\n",
       "       '374_y', '375_y', '376_y', '377_y', '378_y', '379_y', '380_y', '381_y',\n",
       "       '382_y', '383_y'],\n",
       "      dtype='object', length=796)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
